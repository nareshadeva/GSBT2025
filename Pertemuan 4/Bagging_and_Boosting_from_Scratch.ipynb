{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview Materi"
      ],
      "metadata": {
        "id": "byXiDYEFJ3mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jelaskan secara singkat perbedaan antara bagging dan boosting menurut pemahamanmu!\n",
        "\n",
        "Bagging; metode dalam machine learning untuk mengurangi varians dan overfitting dengan cara dataset dibagi menjadi banyak subset yang dimana satu machine learning model yang sama akan mengolah setiap subset lalu di campur hasilnya.\n",
        "\n",
        "Boosting; metode dalam machine learning untuk mengurangi bias namun ada risk membuat overfitting model jika tidak dilakukan tepat dimana sebuah model machine learning dibuat belajar dari kesalahannya. Model akan membuahkan hasil dari dataset lalu sebuah model lain akan belajar dari kesalahannya. Ini akan diulangi terus-menurus tergantung jumlah iterasi yang diinginkan."
      ],
      "metadata": {
        "id": "4UQG5Ang8Ten"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data & Libraries"
      ],
      "metadata": {
        "id": "RqRs22Mu6x5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import semua libraries yang akan dibutuhkan\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, explained_variance_score\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "TOzFusg26xQT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('breast-cancer.csv')\n",
        "\n",
        "# Misal kolom target bernama 'target'\n",
        "X = data.drop('diagnosis', axis=1)  # Semua kolom kecuali 'target'\n",
        "y = data['diagnosis']               # Kolom target saja\n",
        "\n",
        "# Split data 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "EgdVWXb1Jy6J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ubah data ke dalam bentuk dataframe agar bisa ditampilkan dalam .head()\n",
        "target = ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave_points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','perimeter_se','area_se','smoothness_se']\n",
        "df = pd.DataFrame(X, columns=target)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "DIccsE6AGTVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "dc595b04-f6a3-4d7f-bfba-36a7c1c209a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'feature_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3306521205.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ubah data ke dalam bentuk dataframe agar bisa ditampilkan dalam .head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feature_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as5nDHct_hfZ"
      },
      "source": [
        "# Bagging from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier - Sklearn"
      ],
      "metadata": {
        "id": "NSJ7Q1Uc-xct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier() # gunakan RandomForestClassifier dari Sklearn\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "# print score menggunakan metrik accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "pbMEcTKb_DPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d51504-a8bc-4586-b062-5a35851ca6ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest from Scratch\n",
        "Source: https://www.youtube.com/watch?v=kFwe2ZZU7yw"
      ],
      "metadata": {
        "id": "xytLmuIi9xor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1P5zGkr_hfj"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "    def __init__(self, n_trees=10, max_depth=10, min_samples_split=2, n_feature=None, random_state=None):\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth=max_depth\n",
        "        self.min_samples_split=min_samples_split\n",
        "        self.n_features=n_feature\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        for _ in range(self.n_trees):\n",
        "            tree = DecisionTree(min_samples_split=self.min_samples_split,\n",
        "            n_features=self.n_features)\n",
        "\n",
        "            X_sample, y_sample = self._bootstrap_samples(X, y)\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def _bootstrap_samples(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return X[idxs], y[idxs]\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        counter = Counter(y)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "        return most_common\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_preds = np.swapaxes(predictions, 0, 1)\n",
        "        predictions = np.array([self._most_common_label(pred) for pred in tree_preds])\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO698edT_hfm"
      },
      "source": [
        "## Predict Using Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAdbGW6A_hfn"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "clf = RandomForest()\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "# print score menggunakan metrik accuracy\n",
        "print(accuracy(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkpidtS5E6pY"
      },
      "source": [
        "# Boosting From Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwmAGfCZ_hf2"
      },
      "source": [
        "## Gradient Boosting Classifier - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VZr0oG__hf3"
      },
      "outputs": [],
      "source": [
        "# define and train the model using GradientBoostingClassifier from Sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preds = GradientBoostingClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "# print score menggunakan metrik accuracy\n",
        "print(accuracy_score(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_HaYoJ7_hfs"
      },
      "source": [
        "## Gradient Boosting from Scratch with Decision Tree\n",
        "Source: https://www.youtube.com/watch?v=Pq2mmJxjs1o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wK39gf__hft"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class gradientBoostingClassifier:\n",
        "    def __init__(self, lr=0.1, n_estimators=25, base_learner=DecisionTreeRegressor):\n",
        "         self.lr = lr\n",
        "         self.n_estimators = n_estimators\n",
        "         self.base_learner = base_learner\n",
        "\n",
        "    def fit(self, X, y, **params):\n",
        "        self.base_models = []\n",
        "\n",
        "        Fm = np.zeros_like(y, dtype=float)\n",
        "\n",
        "        _, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
        "        axs = axs.flatten()\n",
        "\n",
        "        for i in range(self.n_estimators):\n",
        "            r_i = y - sigmoid(Fm)\n",
        "            h_i = self.base_learner(**params)\n",
        "            h_i.fit(X, r_i)\n",
        "            self.base_models.append(h_i)\n",
        "\n",
        "            # update the model\n",
        "            Fm = Fm + self.lr * h_i.predict(X)\n",
        "\n",
        "            # Plotting\n",
        "            axs[i].plot(y, '.')\n",
        "            axs[i].plot(Fm, '.')\n",
        "            axs[i].set_title(str(i))\n",
        "            axs[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def predict(self, X):\n",
        "        Fm = np.zeros(X.shape[0])\n",
        "        for h_i in self.base_models:\n",
        "            Fm += self.lr * h_i.predict(X)\n",
        "\n",
        "        probs = sigmoid(Fm)\n",
        "\n",
        "        return (probs >= 0.5).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8xpiy5_hfu"
      },
      "source": [
        "## Predict Using Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC2HJn67_hfy"
      },
      "outputs": [],
      "source": [
        "# define and train the model\n",
        "model = GradientBoostingRegressor()\n",
        "r = model.fit(X_train, y_train, max_depth=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwiUpoGa_hfz"
      },
      "outputs": [],
      "source": [
        "# get predictions:\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "# print score menggunakan metrik accuracy\n",
        "score = explained_variance_score(y_test, preds)\n",
        "print(\"score: \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Z77aeoU5_hf0"
      },
      "outputs": [],
      "source": [
        "# plot predictions vs. the ground truth:\n",
        "_, ax = plt.subplots(1, 1)\n",
        "plt.title('test')\n",
        "ax.plot(y_test, 'o', label = 'y_test')\n",
        "ax.plot(preds, 'o', label = 'preds')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python [conda env:jcopml]",
      "language": "python",
      "name": "conda-env-jcopml-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}